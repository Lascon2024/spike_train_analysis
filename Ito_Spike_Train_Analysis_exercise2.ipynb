{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spike Train Analysis: exercise 2 \n",
    "\n",
    "This notebook covers the following topics:\n",
    "\n",
    "* Pairwise correlations and the cross-correlation histogram\n",
    "* Evaluation of statistical significance for peaks of a cross-correlation histogram\n",
    "* Surrogate-based methods of p-value estimation; surrogate types and their features\n",
    "\n",
    "## Suggested data sets\n",
    "In this notebook you will analyse data from pairs of simultaneously recorded spike trains, contained in the folder `'./data/'`.\n",
    "The following pairs are suitable for the pairwise analysis: [`Data28`, `Data29`],[`Data12`, `Data13`], [`Data14`, `Data15`], [`Data20`, `Data21`], [`Data21`, `Data22`], [`Data23`, `Data24`]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import quantities as pq\n",
    "import elephant.spike_train_correlation as corr\n",
    "import elephant.spike_train_surrogates as surr\n",
    "import elephant.statistics as stats\n",
    "import elephant.conversion as conv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Cross-Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Raw cross-correlation histogram\n",
    "The cross-correlation histogram (CCH) is a standard tool to analyse fine-temporal correlations between two (simultaneously recorded) spike trains.\n",
    "The CCH between a reference spike train $x$ and a target spike train $y$ estimates, at each time lag $\\tau$, the tendency of $y$ to spike at time $\\tau$ after a spike in $x$.\n",
    "* Analyse simultaneously recorded spike trains (i.e., [Data28, Data29], [Data12, Data13], [Data14, Data15], [Data20, Data21], [Data21, Data22], [Data23, Data24]) for possible temporal correlations by use of the CCH (see `corr.cross_correlation_histogram()`).\n",
    "* Study the ground truth of each individual dataset by the measure we already learnt, e.g. PSTH, ISI distribution, etc. \n",
    "* Describe the features of the CCHs, and what they mean. Where do the modulations of the entries in the CCH come from, e.g., a bump in the middle? Can you distinguish contributions due to firing rates and fine-temporal correlation?\n",
    "* What are the differences between the CCHs of the data sets? Are all pairs correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "data_id1, data_id2 = 28, 29\n",
    "w = 2 * pq.ms  # binsize for CCH\n",
    "maxlag = 200 * pq.ms  # maximum correlation lag\n",
    "\n",
    "# Load the data\n",
    "data1 = np.load(f'./data/Data{data_id1}.npy', allow_pickle=True, encoding='latin1')\n",
    "data2 = np.load(f'./data/Data{data_id2}.npy', allow_pickle=True, encoding='latin1')\n",
    "spike_trains1 = data1.item()['st']  # List of neo.SpikeTrain objects; one object per trial\n",
    "spike_trains2 = data2.item()['st']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data summary\n",
    "\n",
    "# Compute PSTH\n",
    "psth1 = stats.time_histogram(spike_trains1, binsize=w, output='rate')\n",
    "psth2 = stats.time_histogram(spike_trains2, binsize=w, output='rate')\n",
    "\n",
    "# Compute ISI distribution\n",
    "isis1 = np.concatenate([stats.isi(st).rescale('ms').magnitude for st in spike_trains1])\n",
    "isis2 = np.concatenate([stats.isi(st).rescale('ms').magnitude for st in spike_trains2])\n",
    "isi_bin_edges = np.arange(0, (maxlag + w/2).rescale('ms').magnitude, w.rescale('ms').magnitude)\n",
    "isi_dist1, _ = np.histogram(isis1, bins=isi_bin_edges, density=True)\n",
    "isi_dist2, _ = np.histogram(isis2, bins=isi_bin_edges, density=True)\n",
    "isi_bin_pos = (isi_bin_edges[1:] + isi_bin_edges[:-1]) / 2\n",
    "\n",
    "# Plot the results\n",
    "fig1 = plt.figure(figsize=(12, 8))\n",
    "num_row, num_col = 4, 3\n",
    "\n",
    "ax_raster1 = plt.subplot2grid((num_row, num_col), (0, 0), rowspan=1, colspan=2)\n",
    "ax_raster1.set_title(f\"Data{data_id1}\")\n",
    "ax_raster1.set_xlabel(\"Time (ms)\")\n",
    "ax_raster1.set_ylabel(\"Trial ID\")\n",
    "for i, st in enumerate(spike_trains1):\n",
    "    ax_raster1.plot(st.rescale('ms').magnitude, [i + 1] * len(st), '.', ms=2, color='r')\n",
    "ax_raster1.set_ylim(0, len(spike_trains1) + 1)\n",
    "\n",
    "ax_raster2 = plt.subplot2grid((num_row, num_col), (1, 0), rowspan=1, colspan=2, sharex=ax_raster1)\n",
    "ax_raster2.set_title(f\"Data{data_id2}\")\n",
    "ax_raster2.set_xlabel(\"Time (ms)\")\n",
    "ax_raster2.set_ylabel(\"Trial ID\")\n",
    "for i, st in enumerate(spike_trains1):\n",
    "    ax_raster2.plot(st.rescale('ms').magnitude, [i + 1] * len(st), '.', ms=2, color='b')\n",
    "ax_raster2.set_ylim(0, len(spike_trains2) + 1)\n",
    "\n",
    "ax_psth = plt.subplot2grid((num_row, num_col), (2, 0), rowspan=2, colspan=2, sharex=ax_raster1)\n",
    "ax_psth.set_title(\"PSTH\")\n",
    "ax_psth.set_xlabel(\"Time (ms)\")\n",
    "ax_psth.set_ylabel(\"Firing rate (Hz)\")\n",
    "ax_psth.plot(psth1.times.rescale('ms'), psth1.rescale('Hz'), color='r')\n",
    "ax_psth.plot(psth2.times.rescale('ms'), psth2.rescale('Hz'), color='b')\n",
    "\n",
    "ax_count1 = plt.subplot2grid((num_row, num_col), (0, 2), rowspan=1, colspan=1)\n",
    "ax_count1.set_title(\"Spike count\")\n",
    "ax_count1.set_xlabel(\"Count\")\n",
    "ax_count1.set_ylabel(\"Trial ID\")\n",
    "ax_count1.plot([len(st) for st in spike_trains1], range(1, len(spike_trains1)+1), '.-', ms=5, color='r')\n",
    "\n",
    "ax_count2 = plt.subplot2grid((num_row, num_col), (1, 2), rowspan=1, colspan=1, sharex=ax_count1)\n",
    "ax_count2.set_title(\"Spike count\")\n",
    "ax_count2.set_xlabel(\"Count\")\n",
    "ax_count2.set_ylabel(\"Trial ID\")\n",
    "ax_count2.plot([len(st) for st in spike_trains2], range(1, len(spike_trains2)+1), '.-', ms=5, color='b')\n",
    "\n",
    "ax_isi = plt.subplot2grid((num_row, num_col), (2, 2), rowspan=2, colspan=1)\n",
    "ax_isi.set_title(\"ISI distribution\")\n",
    "ax_isi.set_xlabel(\"ISI (ms)\")\n",
    "ax_isi.set_ylabel(\"Prob. density\")\n",
    "ax_isi.plot(isi_bin_pos, isi_dist1, color='r')\n",
    "ax_isi.plot(isi_bin_pos, isi_dist2, color='b')\n",
    "\n",
    "fig1.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the CCHs across trials\n",
    "num_lags = int((maxlag / w).magnitude)\n",
    "cchs = []\n",
    "for st1, st2 in zip(spike_trains1, spike_trains2):\n",
    "    st1_binned = conv.BinnedSpikeTrain(st1, w)\n",
    "    st2_binned = conv.BinnedSpikeTrain(st2, w)\n",
    "    # cch, lags = corr.cross_correlation_histogram(st1_binned, st2_binned, window=[-num_lags, num_lags], border_correction=False, binary=True)\n",
    "    cch, lags = corr.cross_correlation_histogram(st1_binned, st2_binned, window=[-num_lags, num_lags])\n",
    "    cchs.append(cch)\n",
    "\n",
    "# Average the CCHs over trials (keeping cch_orig to be a neo.AnalogSignal object)\n",
    "cch_orig = cchs[0]\n",
    "for cch in cchs[1:]:\n",
    "    cch_orig += cch\n",
    "cch_orig /= len(cchs)\n",
    "\n",
    "# Plot the result\n",
    "fig2, ax_cch = plt.subplots(1, 1, figsize=(6, 4))\n",
    "ax_cch.set_title(f\"CCH (Data{data_id1} vs. Data{data_id2})\")\n",
    "ax_cch.set_xlabel(\"Time lag (ms)\")\n",
    "ax_cch.set_ylabel(\"Count\")\n",
    "ax_cch.plot(cch.times.rescale('ms'), cch_orig, 'k-', label='raw CCH')\n",
    "ax_cch.legend()\n",
    "ax_cch.grid()\n",
    "fig2.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Correlations above chance level?\n",
    "\n",
    "Deriving the statistical significance of observed correlations is crutial for assessing whether two spike trains are really correlated, or more rigorously, whether the null hypothesis of independence can be rejected. However, it is typically not feasible to assess analytically the statistical significance of spike train correlation. An alternative powerful approach is the surrogate-based estimation of statistical significance. A surrogate is created by randomizing the original data to destroy specific statistical features of the data (here, precise correlation) while keeping other relevant features (e.g. firing rates and/or ISI distribution). \n",
    "\n",
    "* Generate a large number of (e.g. 100) surrogate datasets by spike dithering (see `surr.dithering()`), and compute a CCH for each surrogate\n",
    "* Compare the surrogate CCH with the CCH of the original data: is the latter significant?\n",
    "* Play with the dither parameter: what is an optimal choice? Why? (Compare to the firing rates of the surrogate data...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "surr_method = 'dither_spike_train'\n",
    "dither_width = 8 * pq.ms\n",
    "n_surr = 100\n",
    "\n",
    "# For each data set, generate n_surr surrogates of each trial via spike dithering\n",
    "surr1_dith = [surr.surrogates(st, n=n_surr, surr_method=surr_method, dt=dither_width) for st in spike_trains1]\n",
    "surr2_dith = [surr.surrogates(st, n=n_surr, surr_method=surr_method, dt=dither_width) for st in spike_trains2]\n",
    "\n",
    "# Compute n_surr CCHs, one per pair of surrogate data sets\n",
    "\n",
    "def compute_surrogate_cchs(surr1, surr2, n_surr, w, maxlag):\n",
    "    num_lags = int((maxlag / w).magnitude)\n",
    "    len_cch = 2 * num_lags + 1\n",
    "    cchs_surr = np.zeros((n_surr, len_cch))\n",
    "    for surr_id in range(n_surr):\n",
    "        sts1 = [st[surr_id] for st in surr1]\n",
    "        sts2 = [st[surr_id] for st in surr2]\n",
    "        for st1, st2 in zip(sts1, sts2):\n",
    "            st1_binned = conv.BinnedSpikeTrain(st1, w)\n",
    "            st2_binned = conv.BinnedSpikeTrain(st2, w)\n",
    "            cchs_surr[surr_id] += corr.cross_correlation_histogram(st1_binned, st2_binned, window=(-num_lags, num_lags))[0].reshape(len_cch)\n",
    "        cchs_surr[surr_id] /= len(sts1)\n",
    "    return cchs_surr\n",
    "\n",
    "cchs_dith = compute_surrogate_cchs(surr1_dith, surr2_dith, n_surr, w, maxlag)\n",
    "    \n",
    "# Compute the mean CCH, and the threshold for significance\n",
    "cch_mean_dith = cchs_dith.mean(axis=0)\n",
    "cch_threshold_dith = np.quantile(cchs_dith, 0.95, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original CCH, the mean surrogate CCH, and the significance threshold\n",
    "\n",
    "def plot_cch(data_id1, data_id2, surr_method, cch, surr_cch_mean, cch_threshold, figsize=(8, 5)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.plot(cch.times.magnitude, cch.magnitude, 'k-', label=\"raw CCH\")\n",
    "    ax.plot(cch.times.magnitude, surr_cch_mean, 'g-', label=\"mean surr. CCH\")\n",
    "    ax.plot(cch.times.magnitude, cch_threshold, 'r--', label=\"significance threshold\")\n",
    "    ax.set_title(f\"CCH (Data{data_id1} vs. Data{data_id2}) and significance ({surr_method})\")\n",
    "    ax.set_xlabel(\"Delay (ms)\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_cch(data_id1, data_id2, surr_method, cch_orig, cch_mean_dith, cch_threshold_dith)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Comparison of surrogate types\n",
    "\n",
    "Spike dithering is not the only way to generate surrogate data. Many other methods exist, which destroy/keep different features of the original data (for a comparison study see Louis et al., 2010).\n",
    "\n",
    "Among these methods, a simple approach is *spike time randomisation*, which keeps the number of spikes (and therefore the average firing rate) of the original spike trains, but places each spike randomly within the considered time period.\n",
    "\n",
    "* Generate surrogates of the same spike trains as before by spike time randomisation (see `surr.spike_time_rand()`)\n",
    "* Compute the CCHs of spike time randomisation surrogates, and plot the result. How does it differ from surrogates by dithering?\n",
    "* Discuss which features each method preserves, and what are pros and cons of each.\n",
    "* On which data sets do they work fine, on which not? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "surr_method = 'randomise_spikes'\n",
    "n_surr = 100\n",
    "\n",
    "# Generate surrogates by spike time randomisation (str)\n",
    "surr1_str = [surr.surrogates(st, n=n_surr, surr_method=surr_method) for st in spike_trains1]\n",
    "surr2_str = [surr.surrogates(st, n=n_surr, surr_method=surr_method) for st in spike_trains2]\n",
    "\n",
    "# Compute n_surr CCHs, one per pair of surrogate data sets\n",
    "cchs_str = compute_surrogate_cchs(surr1_str, surr2_str, n_surr, w, maxlag)\n",
    "\n",
    "# Compute the mean CCH, and the threshold for significance\n",
    "cch_mean_str = cchs_str.mean(axis=0)\n",
    "cch_threshold_str = np.quantile(cchs_str, 0.95, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original CCH, the mean surrogate CCH, and the significance threshold\n",
    "plot_cch(data_id1, data_id2, surr_method, cch_orig, cch_mean_str, cch_threshold_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simple alternative technique to generate surrogates is trial shuffling. Each surrogate corresponds to a random shuffle of the trial indices. The philosophy behind is that the processing in the different trials is identical and therefore spike trains of the different neurons from different trials are cross-correlated, but for the testing one only wants to destroy potential spike correlation. Thus we compute in the surrogate the CCH for randomly selected trials of each neuron and compute the average CCH.  \n",
    "* Generate the surrogate data by trial shuffling with different number of shuffles and compute the surrogate CCH.\n",
    "* Compare the surrogate CCH with the CCH of the original data: is the latter significant?\n",
    "* Discuss the results. What feature of the data has been destroyed/conserved with this method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis parameters\n",
    "n_surr = 100\n",
    "\n",
    "# Generate surrogate by trial shuffling\n",
    "num_trials = len(spike_trains1)\n",
    "surr1_shf = [[] for _ in range(num_trials)]\n",
    "surr2_shf = [[] for _ in range(num_trials)]\n",
    "for j in range(n_surr):\n",
    "    random_idx = np.arange(num_trials, dtype=int)\n",
    "    np.random.shuffle(random_idx)\n",
    "    for i, j in enumerate(random_idx):\n",
    "        surr1_shf[i].append(spike_trains1[j])  # shuffle trials only for spike_trains1\n",
    "        surr2_shf[i].append(spike_trains2[i])  # spike_trains2 is just copied with the correct trial order\n",
    "\n",
    "# Compute n_surr CCHs, one per pair of surrogate data sets\n",
    "cchs_shf = compute_surrogate_cchs(surr1_shf, surr2_shf, n_surr, w, maxlag)\n",
    "\n",
    "# Compute the mean CCH, and the threshold for significance\n",
    "cch_mean_shf = cchs_shf.mean(axis=0)\n",
    "cch_threshold_shf = np.quantile(cchs_shf, 0.95, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the original CCH, the average from surrogates and the significance threshold\n",
    "plot_cch(data_id1, data_id2, \"trial_shuffling\", cch_orig, cch_mean_shf, cch_threshold_shf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
